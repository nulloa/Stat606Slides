%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass{beamer}

\mode<presentation> {

% The Beamer class comes with a number of default slide themes
% which change the colors and layouts of slides. Below this is a list
% of all the themes, uncomment each in turn to see what they look like.

%\usetheme{default}
\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
%\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

% As well as themes, the Beamer class has a number of color themes
% for any slide theme. Uncomment each of these in turn to see how it
% changes the colors of your current slide theme.

%\usecolortheme{albatross}
\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

%\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\usepackage{graphicx, copyrightbox, bm, amsmath}
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\makeatletter
\newsavebox{\mybox}\newsavebox{\mysim}
\newcommand{\distras}[1]{%
  \savebox{\mybox}{\hbox{\kern3pt$\scriptstyle#1$\kern3pt}}%
  \savebox{\mysim}{\hbox{$\sim$}}%
  \mathbin{\overset{#1}{\kern\z@\resizebox{\wd\mybox}{\ht\mysim}{$\sim$}}}%
}
\makeatother
%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title[Stat 606]{Approximate Gaussian Process Regression Using Parrallel Processing} % The short title appears at the bottom of every slide, the full title is only on the title page

\author{Nehemias Ulloa} % Your name
\institute[ISU] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
Iowa State University \\ % Your institution for the title page
\medskip
\textit{} % Your email address
}
\date{\today} % Date, can be changed to a custom date

\begin{document}

\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

\begin{frame}
\frametitle{Overview} % Table of contents slide, comment this block out to remove it
\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

%------------------------------------------------
\section{GPU}
%------------------------------------------------

\begin{frame}
\begin{itemize}
\item GPU: Graphics Processing Unit
\item Chips/Processors similar to a CPU but they specialize in graphics
\item First appeared in arcade games
\item Motivation is largely still the same
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}
\begin{itemize}
\item What's the difference from a CPU?
\item Difference is in structure
\item GPU has a structure that is made for parrellelization
\end{itemize}


%\copyrightbox[r]{\includegraphics[height=0.4\textheight]{cpu-and-gpu.jpg}}{Source: NVIDIA}
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\begin{itemize}
\item Most common way to use a GPU is by using NVIDIA's \verb|CUDA| programming model 
\item Send work to the GPU using a {\it kernal} function
\item To write a good kernal function, need to understand the architecture of the GPU. \\
\end{itemize}

Here are the big components of the architecture:
\begin{itemize}
\item Threads - Smallest unit that executes a command 
\item Blocks - Group of 1024 threads per block
\item Kernal Grid - Group of 65,533 Blocks where a kernal fn is invoked 
\item Warp - Groups of threads in a block that simmultaneously execute a command
\item Streaming Multiprocessor(SM) - Wraps for the same block are same SM aka actually runs the CUDA kernals
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\begin{center}
\copyrightbox{\includegraphics[height=0.7\textheight]{cudasoftware.png}}{Source:NVIDIA CUDA Compute Unified Device Architecture Programming Guide Version 1.1}
\end{center}
\end{frame}

%------------------------------------------------

\begin{frame}
We would like to run as many blocks as possible on the SM but that depends on two constraints:
\begin{itemize}
\item Amount of memory - Different for each card
\item Number of registers required by each thread - We have some control \\
\end{itemize}

Ultimately the number of SMs and blocks per SM is defined by the hardware of the GPU. In the paper's example their card had 16 SMs and allowed multiple blocks per SM. \\
\end{frame}

%------------------------------------------------

\begin{frame}
Memory types and locations: \\

\begin{table}
\begin{tabular}{l | c | c}
\hline
Type         & Access   & Size  \\
\hline
Thread/Local & Thread   & Small \\
Shared       & Block    & 48 KB \\
Global       & Everyone & 5 GB   \\
\hline
\end{tabular}
\end{table}

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\begin{center}
\copyrightbox{\includegraphics[height=0.7\textheight]{gpumemory.png}}{Source:NVIDIA CUDA Compute Unified Device Architecture Programming Guide Version 1.1}
\end{center}
\end{frame}

%------------------------------------------------








%------------------------------------------------
\section{Examples}
%------------------------------------------------


%------------------------------------------------
\subsection{Spatial Models with Block Composite Likelihood}
%------------------------------------------------

\begin{frame}[fragile]

Geostatistical model:
\begin{align}
Y(\bm{s}) = \bm{x}^t(\bm{s})\bm{\beta} + w(\bm{s}) + \epsilon(\bm{s})
\end{align}

where 
\begin{itemize}
\item $\bm{s} \in \bm{D}  \subseteq \Re^d$ are spatial locations in 2 or 3 dim space \\
\item $Y(\bm{s})$ Guassian response variable \\
\item $\bm{x}^t(\bm{s})$ is a vector of explanatory variables \\
\item $\epsilon(\bm{s}) \distras{ind} N(0, \tau^2)$ \\
\item $w(\bm{s})$ provides the structural dependence i.e. the covariance structure
\end{itemize}

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
Consider the data at $n$ loacations then we can consider our model like this:
\begin{gather*}
\bm{Y} \sim N(\bm{X\beta},\Sigma) \\
\text{where } \Sigma = \Sigma(\bm{\theta}) = \bm{C} + \tau^2 \bm{I}_n \\
\text{and } C(i,j) = cov(w(\bm{s}_i),w(\bm{s}_j))
\end{gather*}

Then we can consider the log-likelihood as:
\begin{align}
\ell (\bm{Y;\beta,\theta}) = -\frac{1}{2}log|\sigma| - \frac{1}{2}(\bm{Y} - \bm{X\beta})^{t}\Sigma^{-1}(\bm{Y} - \bm{X\beta})
\end{align}

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]

As usual, the most computationally intensive parts will deal with computing $|\Sigma|$ and $\Sigma^{-1}$. One way to handle this is a composite likelihood based on pairwise data differences. \\

This is a natural compromise for geostatistical models; the blocks allow us a good tradeoff between computational and statistical efficiency. \\ 

The basic idea is to split $D$ into $M$ blocks where $\bigcup_k D_k = D$ and $D_k \bigcap D_l = \emptyset$. 
\end{frame}

%------------------------------------------------

\begin{frame}
We can get the likelihood to look like: 

\begin{equation} \label{eq1}
\begin{split}
\ell(\bm{Y};\bm{\beta},\bm{\theta}) & = \sum_{k=1}^{M-1} \sum_{l>k} \ell(\bm{Y}_;\bm{\beta},\bm{\theta}) \\
                                    & = \sum_{k=1}^{M-1} \sum_{l>k} \big[ -\frac{1}{2}\log|\Sigma_{kl}| -\frac{1}{2}(\bm{Y_{kl}} - \bm{X_{kl}\beta})^{t}\Sigma^{-1}_{kl}(\bm{Y_{kl}} - \bm{X_{kl}\beta}) \big]
\end{split}
\end{equation}

where
\begin{itemize}
\item $\bm{Y}_k = \{ Y(\bm(s)_i):\bm(s)_i \in D_k \}$
\item $\bm{Y}_{kl} = (\bm{Y}^t_k, \bm{Y}^t_l)^t$
\item $\bm{X}_{kl} = (\bm{X}^t_k, \bm{X}^t_l)^t$
\item $\bm{\Sigma}_{kl} = $\[
\begin{bmatrix}
    \bm{\Sigma}_{kl}(1,1)  & \bm{\Sigma}_{kl}(1,2) \\
    \bm{\Sigma}_{kl}(2,1)  & \bm{\Sigma}_{kl}(2,2)
\end{bmatrix}
\]
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
In order for this to work well we need to choose blocks carefully. The goal is to minimize the correlation between observations not in a block-pair and maximize the number of blocks simultaneously. \\

Here are some ideas:
\begin{itemize}
\item Block widths equal to the effective spatial range
\item If interested in computation, use equally numbered blocks
\item Block according to spatial dependence
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
Computationally, the Block Composite Likelihood complexity is of $O(n)$.\\

The limit on memory is not an issue since the CL, score, and Hessian calculations are summations over independent calculations for each pair. Since these are independent calculations, they can be parrallelized. 
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
Here are some sample results.\\

\begin{figure}[h]
\centering
\includegraphics[height=0.40\textheight]{gpucpucomparepap1.png}
\caption{This graphics compares CPU-only $\&$ GPU-only times for ALC calculations at $n_{cand}=60000$ ($\sim$ max number of blocks) candidate locations while changing $n$ (sample size).}
\end{figure}
\end{frame}


%------------------------------------------------
\subsection{Gaussian Process Regression}
%------------------------------------------------

\begin{frame}[fragile]

{\bf Def:} Gaussian process a group of random variables where any
subset of them have a joint Gaussian distribution
\begin{itemize}
\item Extend multivariate Gaussian distributions to infinite dimensionality e.g. $\bm{y} =  \{ y_1 , \ldots , y_n \}$ as a single point from a $n$-dim Multivariate Normal
\item Fully defined by a mean function and a covariance function
\item GP Regression is often used in computer emulation i.e. a distribution $Y(x)|D_N$ for new $x$ given simulated data $D_N$ $(p(y(x)|D_N, K_\theta))$
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
We typically assume that the mean function is zero, but there are multiple options for the covariance function. Some popular options are:
\begin{itemize}
\item Squared exponential
\item Matern
\item Noise (i.e. White noise - flat spectrum)
\end{itemize}

The papers used an isotropic Gaussian correlation structure:

$K_{\theta, \eta}(x,x') = exp\{ -\parallel x-x' \parallel ^2 / \theta \}$ \\

\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
\begin{itemize}
\item Problem is that computations are at $O(N^3)$ 
\item One of the most common ways to handle this is to use sparsity
\item Gramacy and Apley(2014) sparsity scheme for accurate and fast predictions
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
Here is the intuition behind the scheme:

\begin{itemize}
\item Focus on the prediction problem at some $x$
\item Data far away from prediction point won't have much influence
\item Use a subdesign $D_n(x) \equiv D_n(X_n(x))$
\item Most common option is Nearest Neighbors(NN), but it has issues
\item A criteria that cycles through possible $D_n(x)$ until optimal is found
\item This is done with no extra computational cost compared to NN
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]

We get the criterion(ALC) by minimizing the Emperical Bayes mean-square prediction error (MSPE): \\
\begin{align}
 J(x_{j+1}, x) = E \{ [ Y(x) - \mu_{j+1}(x|D_{j+1}, \hat{\theta}_{j+1}) ] ^2| D_{j}(x) \} \label{eq:4}
\end{align}  
where $j < n$ and $\hat{\theta}_{j+1}$ is the est of $\theta$ on $D_{j+1}$ \\

\begin{align}
J(x_{j+1}, x) \approx V_{j}(x|x_{j+1}, \hat{\theta}_{j}) + \left( \frac{\delta \mu_{j}(x;\theta)}{\delta \theta} \Big|_{\theta = \hat{\theta}_j} \right) ^2 / G_{j+1}(\hat{\theta}_j)
\end{align}
\begin{multline}
V_j(x|x_{j+1};\theta) = \frac{(j+1)\psi_j}{j(j-1)}\upsilon_{j+1}(x_j; \theta) \\
\text{where } \upsilon_{j+1}(x_j; \theta) = \big[ K_{j+1}(x,x) - k^{T}_{j+1}(x)K^{-1}_{j+1}k^{T}_{j+1}(x) \big]
\end{multline}
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
The first part of the Eq \ref{eq:4} estimates the predictive variance at $x$ after we include $x_{j+1}$ in the design and the second part estimates the rate of change in the predictive mean at $x$ weighted by the expectation of the future inverse information after $x_{j+1}$ and $y_{j+1}$ are added to the design. \\

Actually, minimizing the first term of Eq \ref{eq:4} is the same as minimizing all of Eq \ref{eq:4}. So we just need to maximize:
\begin{align}
\upsilon_{j}(x; \theta) - \upsilon_{j+1}(x; \theta)
\end{align}
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
Putting it all together, we get this algorithm:
\begin{enumerate}
\item Choose starting global $\theta_x = \theta_0$ for all x
\item Calculate local design $X_n(x, \theta_x)$ based on ALC, for each x (independently)
 \begin{enumerate}[(a)]
 \item Choose NN design, $X_{n_0}(x)$ of size $n_0$
 \item For $j = n_0,\ldots,n-1$, set
 \begin{align*}
 x_{j+1} = \text{arg } \max\limits_{x_{j+1} \in X_N \backslash X_j(x)} \upsilon_{j}(x; \theta) - \upsilon_{j+1}(x; \theta),\\
 \text{then update } D_{j+1}(x,\theta_x) = D_j(x,\theta_x) \cup (x_{j+1}, y(x_{j+1}))
 \end{align*}
 \end{enumerate}
\item Independently, calculate $\hat{\theta}_n(x)|D_n(x,\theta_x$. Set $\theta_x = \hat{\theta}_n(x)$
\item Repeat steps 2-3
\item Output predictions $Y(x)|D_n(x,\theta_x)$
\end{enumerate}
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
From the algorithm outline, we can see that step 2.b. is the hardest to compute. This is where using the GPU comes in! \\

Note that each candidate's($x_{j+1}$) calculations can computed independent of each other. This allows us to give each block it's own candidate. From there we give $j$ threads their own sequence of calculations.
\end{frame}

%------------------------------------------------

\begin{frame}[fragile]
Here are some sample results.\\

\begin{figure}[h]
\centering
\includegraphics[height=0.65\textheight]{gpucpucomparepap2.png}
\caption{This graphics compares CPU-only $\&$ GPU-only times for ALC calculations at $n_{cand}=60000$ ($\sim$ max number of blocks) candidate locations while changing $n$ (sample size).}
\end{figure}
\end{frame}





%------------------------------------------------
\subsection{Using own GPU}
%------------------------------------------------

\begin{frame}[fragile]
The writers of the last paper created a \verb|R| package \verb|laGP| in order to easily implement the CUDA, C, and R subroutines.

\end{frame}



\end{document}